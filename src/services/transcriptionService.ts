// F3: å‹•ç”»â†’å°æœ¬å¤‰æ›æ©Ÿèƒ½
import { Script, ScriptSegment } from '../types';
import * as fs from 'fs';
import * as path from 'path';
import { spawn } from 'child_process';
import Anthropic from '@anthropic-ai/sdk';

const WHISPER_MODEL = 'whisper-1';

export class TranscriptionService {
  private anthropic: Anthropic;
  private openaiApiKey: string;
  private tempDir: string;

  constructor() {
    this.anthropic = new Anthropic({
      apiKey: process.env.ANTHROPIC_API_KEY || ''
    });
    this.openaiApiKey = process.env.OPENAI_API_KEY || '';
    this.tempDir = './temp';
    this.ensureTempDir();
  }

  private ensureTempDir(): void {
    if (!fs.existsSync(this.tempDir)) {
      fs.mkdirSync(this.tempDir, { recursive: true });
    }
  }

  /**
   * å‹•ç”»ã‚’å°æœ¬ã«å¤‰æ›
   */
  async transcribeVideo(videoPath: string, language: string = 'ja'): Promise<Script> {
    console.log(`ğŸ“ Transcribing video: ${videoPath}`);

    // Step 1: éŸ³å£°æŠ½å‡º
    const audioPath = await this.extractAudio(videoPath);

    // Step 2: éŸ³å£°èªè­˜
    let segments: ScriptSegment[];
    try {
      segments = await this.transcribeWithWhisper(audioPath, language);
    } catch (error) {
      console.warn('Whisper failed, trying local transcription');
      segments = await this.transcribeLocal(audioPath);
    }

    // Step 3: å°æœ¬æ§‹é€ åŒ–
    const fullText = segments.map(s => s.text).join('\n');
    const structuredScript = await this.structureScript(fullText);

    // Cleanup
    this.cleanup(audioPath);

    return {
      full_text: fullText,
      segments,
      summary: structuredScript.summary,
      keywords: structuredScript.keywords
    };
  }

  /**
   * å‹•ç”»ã‹ã‚‰éŸ³å£°ã‚’æŠ½å‡º
   */
  private async extractAudio(videoPath: string): Promise<string> {
    const outputPath = path.join(this.tempDir, `audio_${Date.now()}.wav`);

    return new Promise((resolve, reject) => {
      const ffmpeg = spawn('ffmpeg', [
        '-i', videoPath,
        '-vn',
        '-acodec', 'pcm_s16le',
        '-ar', '16000',
        '-ac', '1',
        '-y',
        outputPath
      ]);

      ffmpeg.on('close', (code) => {
        if (code === 0) {
          resolve(outputPath);
        } else {
          reject(new Error(`FFmpeg failed with code ${code}`));
        }
      });

      ffmpeg.on('error', reject);
    });
  }

  /**
   * Whisper APIã§éŸ³å£°èªè­˜
   */
  private async transcribeWithWhisper(audioPath: string, language: string): Promise<ScriptSegment[]> {
    if (!this.openaiApiKey) {
      throw new Error('OpenAI API key not set');
    }

    const audioData = fs.readFileSync(audioPath);
    const blob = new Blob([audioData], { type: 'audio/wav' });

    const formData = new FormData();
    formData.append('file', blob, 'audio.wav');
    formData.append('model', WHISPER_MODEL);
    formData.append('language', language);
    formData.append('response_format', 'verbose_json');
    formData.append('timestamp_granularities[]', 'segment');

    const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${this.openaiApiKey}`
      },
      body: formData
    });

    if (!response.ok) {
      throw new Error(`Whisper API error: ${response.status}`);
    }

    const data = await response.json();

    return (data.segments || []).map((seg: any) => ({
      start_time: seg.start,
      end_time: seg.end,
      text: seg.text.trim()
    }));
  }

  /**
   * ãƒ­ãƒ¼ã‚«ãƒ«éŸ³å£°èªè­˜ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
   */
  private async transcribeLocal(audioPath: string): Promise<ScriptSegment[]> {
    // whisper.cpp ã¾ãŸã¯ä»–ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
    return new Promise((resolve) => {
      const whisper = spawn('whisper', [
        audioPath,
        '--model', 'base',
        '--language', 'ja',
        '--output_format', 'json',
        '--output_dir', this.tempDir
      ]);

      whisper.on('close', () => {
        const jsonPath = audioPath.replace('.wav', '.json');
        if (fs.existsSync(jsonPath)) {
          const data = JSON.parse(fs.readFileSync(jsonPath, 'utf-8'));
          resolve(data.segments?.map((seg: any) => ({
            start_time: seg.start,
            end_time: seg.end,
            text: seg.text.trim()
          })) || []);
        } else {
          // æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ç©ºã®çµæœ
          resolve([{
            start_time: 0,
            end_time: 0,
            text: '[éŸ³å£°èªè­˜ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§å°æœ¬ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„]'
          }]);
        }
      });

      whisper.on('error', () => {
        resolve([{
          start_time: 0,
          end_time: 0,
          text: '[éŸ³å£°èªè­˜ãƒ„ãƒ¼ãƒ«ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“]'
        }]);
      });
    });
  }

  /**
   * Claude APIã§å°æœ¬ã‚’æ§‹é€ åŒ–
   */
  private async structureScript(text: string): Promise<{ summary: string; keywords: string[] }> {
    try {
      const response = await this.anthropic.messages.create({
        model: 'claude-sonnet-4-20250514',
        max_tokens: 1024,
        messages: [
          {
            role: 'user',
            content: `ä»¥ä¸‹ã®å‹•ç”»å°æœ¬ã‚’åˆ†æã—ã€JSONã§è¿”ã—ã¦ãã ã•ã„ï¼š

å°æœ¬:
${text}

å‡ºåŠ›å½¢å¼:
{
  "summary": "100æ–‡å­—ä»¥å†…ã®è¦ç´„",
  "keywords": ["ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰1", "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰2", ...]
}

JSONã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚`
          }
        ]
      });

      const content = response.content[0];
      if (content.type === 'text') {
        const parsed = JSON.parse(content.text);
        return {
          summary: parsed.summary || '',
          keywords: parsed.keywords || []
        };
      }
    } catch (error) {
      console.error('Claude API error:', error);
    }

    // ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    return {
      summary: text.slice(0, 100) + '...',
      keywords: this.extractKeywordsSimple(text)
    };
  }

  /**
   * ç°¡æ˜“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æŠ½å‡º
   */
  private extractKeywordsSimple(text: string): string[] {
    const words = text
      .replace(/[ã€‚ã€ï¼ï¼Ÿ\n]/g, ' ')
      .split(/\s+/)
      .filter(w => w.length >= 2);

    const freq: Record<string, number> = {};
    words.forEach(w => {
      freq[w] = (freq[w] || 0) + 1;
    });

    return Object.entries(freq)
      .sort((a, b) => b[1] - a[1])
      .slice(0, 10)
      .map(([word]) => word);
  }

  /**
   * ãƒ†ãƒ³ãƒãƒ©ãƒªãƒ•ã‚¡ã‚¤ãƒ«ã®å‰Šé™¤
   */
  private cleanup(filePath: string): void {
    try {
      if (fs.existsSync(filePath)) {
        fs.unlinkSync(filePath);
      }
    } catch {
      // Ignore cleanup errors
    }
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ç›´æ¥å°æœ¬ã‚’ç”Ÿæˆï¼ˆå‹•ç”»ãªã—ã®å ´åˆï¼‰
   */
  async createScriptFromText(text: string): Promise<Script> {
    const structured = await this.structureScript(text);

    return {
      full_text: text,
      segments: [{
        start_time: 0,
        end_time: 0,
        text
      }],
      summary: structured.summary,
      keywords: structured.keywords
    };
  }

  /**
   * å°æœ¬ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆå‡ºåŠ›
   */
  formatScript(script: Script): string {
    let output = '# å‹•ç”»å°æœ¬\n\n';
    output += `## è¦ç´„\n${script.summary}\n\n`;
    output += `## ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰\n${script.keywords.join(', ')}\n\n`;
    output += `## å…¨æ–‡\n${script.full_text}\n\n`;

    if (script.segments.length > 1) {
      output += '## ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ã\n';
      script.segments.forEach(seg => {
        const start = this.formatTime(seg.start_time);
        const end = this.formatTime(seg.end_time);
        output += `[${start} - ${end}] ${seg.text}\n`;
      });
    }

    return output;
  }

  /**
   * æ™‚é–“ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
   */
  private formatTime(seconds: number): string {
    const mins = Math.floor(seconds / 60);
    const secs = Math.floor(seconds % 60);
    return `${mins.toString().padStart(2, '0')}:${secs.toString().padStart(2, '0')}`;
  }
}

export const transcriptionService = new TranscriptionService();
